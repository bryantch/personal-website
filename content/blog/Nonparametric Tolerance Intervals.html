---
title: "Nonparametric Tolerance Intervals - Part I"
author: "Bryant Chen"
date: 2022-01-02
categories: ["Mathematical Statistics"]
tags: ["Simulation", "Nonparametric", "Tolerance"]
description: A method for constructing a nonparametric tolerance interval.
output:
  pdf_document: default
  html_document: default
---

<script src="Nonparametric Tolerance Intervals_files/header-attrs/header-attrs.js"></script>


<p><strong>Introduction</strong></p>
<p>This first post is going to be about a method of constructing Nonparametric Tolerance Intervals with a focus on it’s derivation, simulation and application to real data. In particular, Wilk’s method for determining the limits based on order statistics, is covered here.</p>
<p>First, what is a tolerance interval? A tolerance interval is different from the familiar confidence interval and even a prediction interval in that a tolerance interval</p>
<p>It is assumed that the reader is familiar with mathematical statistics when it comes to the derivation section.</p>
<p>devise one-sided tolerance limits
, similar to confidence limits</p>
<p>In other words,</p>
<p><strong>Derivation</strong></p>
<p>Suppose we have a sequence of random variables that follow some probability distribution -</p>
<p><span class="math display">\[X_1,X_2,...,X_n \sim f(x)\]</span> where <span class="math inline">\(f(x)\)</span> is unknown and -
<span class="math display">\[X_{(1)},X_{(2)},...,X_{(n)}\]</span> are the order statistics while <span class="math inline">\(x_{(1)},x_{(2)},...,x_{(n)}\)</span> is the ordered sample.</p>
<p>For a two-sided tolerance interval, we want an interval for some population, <span class="math inline">\(p\)</span> and confidence level, <span class="math inline">\(1-a\)</span>, such that -</p>
<p><span class="math display">\[P \left[ \Bigl\{ P[X \leq LL] \leq \frac{(1-p)}{2} \Bigr\} \cap \Bigl\{P[X \geq UL] \leq \frac{(1-p)}{2} \Bigr\} \right]= 1-a \]</span>
We define <span class="math inline">\(LL\)</span> and <span class="math inline">\(UL\)</span> to be the values of the order statistics that satisfies <span class="math inline">\((F_X(UL) - F_X(LL)) \geq p\)</span>. So that means we need to find ranks, <span class="math inline">\(d\)</span> and <span class="math inline">\(c\)</span>, such that <span class="math inline">\(F(X_{(d)}) - F(X_{(c)}) \geq p\)</span> which is equivalent to the following -</p>
<p><span class="math display">\[F(X_{(d)}) - F(X_{(c)}) \geq p \leftrightarrow \left[1 - \int_{X_{(c)}}^{X_{(d)}} f(x) dx \geq p \right]\]</span> where <span class="math inline">\(F\)</span> is the cumulative distribution function of the unknown population. We set <span class="math inline">\(W = F(X_{(d)}) - F(X_{(c)})\)</span> so <span class="math inline">\(W\)</span> is a random variable.</p>
<p>It can be shown that the <span class="math inline">\(kth\)</span> smallest order statistic follows a Beta Distribution, <span class="math inline">\(Beta(\alpha,\beta)\)</span>, with <span class="math inline">\(\alpha = k\)</span> and <span class="math inline">\(\beta = n - k + 1\)</span>.</p>
<p><span class="math display">\[X_{(k)} \sim Beta(k,n-k+1)\]</span>
<span class="math display">\[c = r\]</span>
<span class="math display">\[d = n-r+1\]</span>
<span class="math display">\[d-c = n - r+1-r = n-2r+1 = a\]</span>
<span class="math display">\[n-(n-2r+1)+1 = n-n+2r-1+1 = 2r = b\]</span>
<span class="math display">\[\rightarrow X_{(d-c)} \sim Beta(a = n-2r+1, b = 2r)\]</span>
So since <span class="math inline">\(W\)</span> is a function of the range between the order statistics with ranks <span class="math inline">\(d\)</span> and <span class="math inline">\(c\)</span>, we can say <span class="math inline">\(W \sim Beta(d-c,n-d+c+1)\)</span>.</p>
<p><span class="math display">\[\rightarrow P[W \geq p] = 1-\alpha \leftrightarrow P[W \leq p] = \alpha\]</span>
<span class="math display">\[\leftrightarrow P[Beta(d - c,n-d + c +1) \leq p] = \alpha\]</span>
Note: No distribution about the population is assumed but the Beta distribution used here, arises due to being able to characterize an order statistic’s distribution with the Beta distribution so it is independent of the population’s distribution. Order statistics are central to nonparametric methods and are utilized often</p>
<p>We can simplify this a bit by assuming symmetry of the ranks from their endpoints. For example, if <span class="math inline">\(n = 65\)</span> then <span class="math inline">\(x_{(2)}\)</span> and <span class="math inline">\(x_{(64)},x_{(3)},...,x_{(k)}\)</span> and <span class="math inline">\(x_{(n-k+1)}\)</span> are symmetric with each other in ranks.</p>
<p>To do this, we take <span class="math inline">\(c = r\)</span> and <span class="math inline">\(d = n-r+1\)</span> so that we end up with -</p>
<p><span class="math display">\[P[Beta(d-c,n-d+c+1) \leq p] = \alpha \rightarrow P[Beta(n-2r+1,2r) \leq p] = \alpha\]</span>
From here, we simply use the cumulative distribution function (CDF) of the Beta distribution which is the regularized incomplete beta function, <span class="math inline">\(I_x(a,b)\)</span>, to find the ranks of our sorted data that ensures the CDF at <span class="math inline">\(p\)</span> evaluates to <span class="math inline">\(\alpha\)</span> so that we can take the complement of this which would give us our confidence level, <span class="math inline">\(1-\alpha\)</span>.</p>
<p>The regularized incomplete beta function, evaluated at the ranks is -</p>
<p><span class="math display">\[I_p(n-2r+1,2r) = \frac{\int_0^{p} t^{n-2r+1-1}(1-t)^{2r-1}dt}{\int_0^{1} t^{n-2r+1-1}(1-t)^{2r-1}dt}\]</span></p>
<p>If <span class="math inline">\(r = 1\)</span> then this simplifies to -</p>
<p><span class="math display">\[\frac{\int_0^{p} t^{n-2r+1-1}(1-t)^{2r-1}dt}{\int_0^{1} t^{n-2r+1-1}(1-t)^{2r-1}dt} = \frac{\frac{np^{(n-1)} + p^n(n-1)}{(n-1)n}}{\frac{1}{(n-1)n}} = np^{(n-1)}+p^n(n-1)\]</span>
<span class="math display">\[\leftrightarrow 1-np^{(n-1)} + p^n(n-1) = 1-\alpha\]</span>
If <span class="math inline">\(r \ne 1\)</span>, meaning we do not want to use the smallest and largest sample values for coverage but instead the 2nd smallest and largest or 3rd smallest and largest, etc. then this is the generalized case for that. It is analytically difficult to solve so numerical methods are most likely required. That said, this is not required if we inted to use the smallest and largest values of our sample for bounding the population no matter how large our sample size is. However, by closely examining this expression, we can see that more samples would be required to bound the population using higher order ranks in order to achieve the same level of confidence using the minimum and maximum of the sample.</p>
<p><span class="math display">\[1 - \frac{\int_0^p t^{n-2r}(1-t)^{2r-1}dt}{\int_0^1 t^{n-2r}(1-t)^{2r-1}dt} = 1 - \alpha\]</span>
This method has been verified via simulation with various mockup populations to demonstrate that, indeed, <span class="math inline">\(1-\alpha %\)</span> of intervals computed under this method contains at least the specified proportion of the population, regardless of the population’s distribution which we showcase in the next section.</p>
<p><em>Sample Size Formulation</em>
We now have a sample size formula to determine the number of samples to gather that will bound the population within at least a proportion, <span class="math inline">\(p\)</span>, with a level of confidence, <span class="math inline">\(1-\alpha\)</span> when using the smallest and largest sample values. Simply iterate through <span class="math inline">\(n\)</span> for a desired proportion coverage until the level of confidence is achieved.</p>
<p><span class="math display">\[1 - np^{(n-1)} + p^n(n-1) = 1 - \alpha\]</span>
<strong>Simulation</strong></p>
<pre class="r"><code>library(tolerance)

population = c(rnorm(500,mean = 25,sd = 2),rlnorm(500,meanlog = 3,sdlog = sqrt(.25))) # fake population
hist(population)</code></pre>
<p><img src="/blog/Nonparametric%20Tolerance%20Intervals_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>our_sample = sample(x = population,size = 65,replace = FALSE)
hist(our_sample)

tolerance::nptol.int(our_sample,alpha = .10,P = .90,side = 2,method = &quot;WILKS&quot;)</code></pre>
<pre><code>##   alpha   P 2-sided.lower 2-sided.upper
## 1   0.1 0.9       9.39607      32.41164</code></pre>
<pre class="r"><code>tolerance::normtol.int(our_sample, alpha = .10,P = .10,side = 2,method = &quot;HE&quot;)</code></pre>
<pre><code>##   alpha   P    x.bar 2-sided.lower 2-sided.upper
## 1   0.1 0.1 22.49472      21.64865       23.3408</code></pre>
<pre class="r"><code>n = 1000 # of iterations
intervals = matrix(data = NA, nrow = n, ncol = 3)
bad_intervals = matrix(data = NA, nrow = n, ncol = 3) # showing what happens if you assume the wrong distribution
results = c()
bad_results = c()

for (i in 1:n){
  our_sample = sample(population,size = 65,replace = FALSE)
  intervals[i,1] = nptol.int(our_sample,alpha = .03,P = .92,side = 2,method = &quot;WILKS&quot;)[3]$&#39;2-sided.lower&#39;
  intervals[i,2] = nptol.int(our_sample,alpha = .03,P = .92,side = 2,method = &quot;WILKS&quot;)[4]$&#39;2-sided.upper&#39;
  intervals[i,3] = length(population[population &lt;= intervals[i,2]])/1000 - length(population[population &lt;= intervals[i,1]])/1000
  
  bad_intervals[i,1] = normtol.int(x = our_sample,alpha = .10,P = .9,side = 2,method = &quot;HE&quot;)$&#39;2-sided.lower&#39;
  bad_intervals[i,2] = normtol.int(x = our_sample,alpha = .10,P = .9,side = 2,method = &quot;HE&quot;)$&#39;2-sided.upper&#39;
  bad_intervals[i,3] = length(population[population &lt;= bad_intervals[i,2]])/1000 - length(population[population &lt;= bad_intervals[i,1]])/1000
  
  if(intervals[i,3] &lt; .92){
    results[i] = FALSE
  } else (results[i] = TRUE)
  
  if(bad_intervals[i,3] &lt; .92){
    bad_results[i] = FALSE
  } else (bad_results[i] = TRUE)
}

#intervals
sum(results)/n # confidence level</code></pre>
<pre><code>## [1] 0.98</code></pre>
<pre class="r"><code>sum(bad_results)/n # confidence level</code></pre>
<pre><code>## [1] 0.629</code></pre>
<pre class="r"><code># Number of samples vs. confidence lvl vs. population coverage

ss = c(seq(40,120,by = 10))
pc = c(seq(.80,.99,by = .03))
cl = c()

cl = matrix(data = NA, nrow = length(ss),ncol = length(pc))
for(i in 1:length(ss)){
  for (j in 1:length(pc)){
    cl[i,j] = 1-ss[i]*pc[j]^(ss[i]-1) + (pc[j]^ss[i])*(ss[i]-1)
  }
}

row.names(cl) = ss
colnames(cl) = pc
cl</code></pre>
<pre><code>##           0.8      0.83      0.86      0.89      0.92      0.95      0.98
## 40  0.9985378 0.9946719 0.9819834 0.9438091 0.8405507 0.6009359 0.1904625
## 50  0.9998073 0.9989891 0.9951488 0.9788353 0.9172880 0.7205682 0.2642286
## 60  0.9999755 0.9998146 0.9987352 0.9922644 0.9582287 0.8084466 0.3380961
## 70  0.9999970 0.9999668 0.9996778 0.9972337 0.9793173 0.8707922 0.4095594
## 80  0.9999996 0.9999942 0.9999193 0.9990270 0.9899133 0.9139462 0.4770265
## 90  1.0000000 0.9999990 0.9999801 0.9996621 0.9951396 0.9432720 0.5395680
## 100 1.0000000 0.9999998 0.9999951 0.9998839 0.9976807 0.9629188 0.5967283
## 110 1.0000000 1.0000000 0.9999988 0.9999605 0.9989022 0.9759324 0.6483834
## 120 1.0000000 1.0000000 0.9999997 0.9999866 0.9994839 0.9844728 0.6946347</code></pre>
<pre class="r"><code>library(lattice)</code></pre>
<p><img src="/blog/Nonparametric%20Tolerance%20Intervals_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<pre class="r"><code>wireframe(cl,
          zlab = &#39;1-a&#39;,
          xlab = &#39;n&#39;,
          ylab = &#39;p&#39;, scales = list(arrows = FALSE),
          drape = TRUE, colorkey = TRUE, main = &quot;Confidence Level vs. Population Coverage vs. Sample Size&quot;)</code></pre>
<p><img src="/blog/Nonparametric%20Tolerance%20Intervals_files/figure-html/unnamed-chunk-1-3.png" width="672" /></p>
<p><strong>Example Application</strong></p>
<p><strong>References</strong></p>
<ol style="list-style-type: decimal">
<li>Wilk’s Formula Applied to Computational Tools: A Practical Discussion and Verification</li>
<li></li>
<li></li>
</ol>
